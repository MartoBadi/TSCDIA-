{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "67596709-1ff5-463b-b84c-e64a5ab6a1ad",
   "metadata": {},
   "source": [
    "## Objetivo:\n",
    "Realizar un modelado completo para un problema de clasificación y un problema de regresión, comparando diferentes técnicas y procedimientos explicados durante el desarrollo de la materia.\n",
    "## Instrucciones Generales:\n",
    "1.\tCada grupo deberá **elegir un dataset de clasificación y otro de regresión** (cada grupo deberá trabajar con datasets distintos). Se les sugiere usar datasets de fuentes como Kaggle, UCI Machine Learning Repository o cualquier otro repositorio que consideren relevante.\n",
    "2.\tEl objetivo es comparar distintos modelos y técnicas vistas en la materia. Deberán aplicar técnicas de preprocesamiento, selección de características, y validar el rendimiento de los modelos elegidos utilizando las métricas adecuadas.\n",
    "3.\tEl trabajo se debe entregar en formato Jupyter Notebook, o cualquier otro que consideren conveniente, e incluir todas las etapas de un análisis de minería de datos, desde la exploración inicial hasta la evaluación del rendimiento de los modelos.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cee8fce8-2a47-4814-9df3-41b1bc820910",
   "metadata": {},
   "source": [
    "## Secciones del Trabajo Práctico\n",
    "**1. Descripción del Problema:**\n",
    "* Describir el problema de clasificación y regresión seleccionados.\n",
    "* Comenzar efectuando un resumen del dataset y de sus características (para entenderlo antes de comenzar a trabajar con él).\n",
    "* Justificar por qué los datasets son adecuados para aplicar los modelos vistos en la materia.\n",
    "* Detallar el objetivo del análisis para cada dataset (ej. ¿Qué se espera predecir?).\n",
    "\n",
    "**2. Análisis Exploratorio de Datos (EDA):**\n",
    "* Realizar una exploración inicial de los datasets.\n",
    "    * Estadísticas descriptivas: revisar los datos, dimensiones de los datos, tipos de datos, resumen (media, desviación estándar, mediana, etc.)\n",
    "    * Distribución entre clases.    \n",
    "    * Asimetría.\n",
    "    * Visualización de distribuciones de variables (Histograma, Gráfico de Densidad o KDE).\n",
    "    * Obtención de Matriz y Visualización de correlaciones entre variables.\n",
    "    * Visualización de la matriz de dispersión (regresión) y matriz de dipersión por clase (clasificación).\n",
    "    * Boxplots (regresión) y Boxplots por clase (clasificación).\n",
    "* Identificar valores atípicos y valores faltantes. \n",
    "* Manejo de valores faltantes, limpiar los datos, eliminación de duplicados, corrección de inconsistencias de formato (si los hubiera), según sea necesario explicando el proceso.\n",
    "\n",
    "**3. Preprocesamiento de Datos:**\n",
    "* Dividir el dataset en entrenamiento y prueba (train/test split).\n",
    "* Aplicar por lo menos 1 técnica de transformación de datos (pueden ser de las vistas en clase u otras que consideren convenientes, pueden ser 2 o más también):\n",
    "  * Escalamiento, estandarización o normalización.\n",
    "  * Binarización.\n",
    "  * Box-Cox o Yeo-Johnson.\n",
    "  * Codificación de variables categóricas (para los atributos que lo requieran tanto en clasificación como en regresión, y para el atributo clase para problemas de clasificación, en caso de ser necesario). --> Usar Label Encoding, One-Hot Encoding o Target Encoding.\n",
    "  * **En caso de aplicar 2 o más transformaciones al conjunto de datos es importante el orden en el que se aplican. ej: 1ro Box-Cox / 2do estandarización.**\n",
    "* **Es importante que las transformaciones se ajusten solo con los datos de entrenamiento y luego se apliquen al conjunto de prueba.**\n",
    "* Visualizar (el DF y también gráficamente) el antes y después de cada transformación aplicada.\n",
    "* Aplicar al problema de regresión 1 técnica (a elección del grupo) entre todas las vistas de Feature Selection y Feature Importance.\n",
    "* Aplicar al problema de clasificación 1 técnica (a elección del grupo) entre todas las vistas de Feature Selection y Feature Importance (la técnica debe ser distinta a la elegida para el problema de regresión).\n",
    "* Deberá aplicar, tanto para el problema de clasificación como para el de regresión, la técnica de Reducción de Dimensiones (PCA)\n",
    "\n",
    "**4. Entrenamiento y Comparación de Modelos:**\n",
    "* Para regresión deberá implementar *LinearRegression* como modelo de taxonomía lineal y un modelo de taxonomía no lineal (a elección del grupo).\n",
    "* Para clasificación deberá implementar *LogisticRegression* como modelo de taxonomía lineal y un modelo de taxonomía no lineal (a elección del grupo).\n",
    "* Comparar cada modelo (2 para regresión y 2 para clasificación) mediante:\n",
    "    * Validación cruzada k-fold con n_splits=10.\n",
    "    * Utilizar el mismo scoring en 'cross_val_score' para todos los modelos por igual. Pueden utilizar algunas de las métricas relevantes vistas en clase: 'accuracy' o 'roc_auc' (para clasificación) y 'neg_mean_absolute_error', 'neg_mean_squared_error' o 'r2' (para regresión).\n",
    "    * Deberán comparar cada modelo, según lo indicado anteriormente, con todas las características, luego con las características seleccionadas por Feature Selection/Importance y por último con las componentes principales obtenidas al aplicar PCA (obtendrán de este proceso 12 modelos en total, 6 para regresión y 6 para clasificación).\n",
    "\n",
    "**5. Optimización de Hiperparámetros y Selección del Mejor Modelo:**\n",
    "* *Aquí vendría la etapa de Optimización de Hiperparámetros que no realizaremos. Deberían seleccionarse los modelos más prometedores y en función de la modificación de sus hiperparámetros quedarnos con el mejor modelo.*\n",
    "* Lo que sí realizaremos es: De todos los modelos entrenados y comparados deberán seleccionar 1 para regresión y 1 para clasificación. **Deberán fundamentar el motivo de la selección aplicada** (ya sea por mejor rendimiento, mejor eficiencia computacional, etc...).\n",
    "\n",
    "**6. Entrenar el modelo con el conjunto de entrenamiento completo:**\n",
    "* Deberán entrenar tanto el modelo de regresión como el de clasificación con todo el conjunto de entrenamiento.\n",
    "\n",
    "**7. Evaluación Final del Modelo:**\n",
    "* Evaluar los modelos con los conjuntos de datos de test no utilizados previamente.\n",
    "* Para regresión deberá implementar la misma métrica de evaluación que la elegida en el punto 4 ('neg_mean_absolute_error', 'neg_mean_squared_error' o 'r2').\n",
    "* Para clasificación deberá presentar el Reporte de clasificación (obtener conclusiones del mismo).\n",
    "\n",
    "**8. Entrenar con todos los datos disponibles (opcional antes de producción):**\n",
    "* Una vez que hemos validado y evaluado el modelo, podemos entrenarlo con **todos los datos disponibles** (entrenamiento + prueba) para tener un modelo más robusto antes de pasarlo a producción.\n",
    "\n",
    "**Conclusiones:**\n",
    "* Comparar los modelos y sacar conclusiones sobre cuál fue el más adecuado para cada tarea. \n",
    "* Expresar las limitaciones del análisis y posibles mejoras.\n",
    "## Grupos:\n",
    "* Serán 5 grupos de 4 integrantes y 1 grupo de 5 integrantes (la clase del 28 de Mayo deben presentar por grupos los datasets con los que trabajarán).\n",
    "* Entrega del trabajo realizado: Según lo indicado en el Aula Virtual.\n",
    "\n",
    "## Criterios de Evaluación: \n",
    "\n",
    "* Claridad en la explicación de los pasos y las técnicas aplicadas.\n",
    "* Justificación de la elección de los modelos y técnicas.\n",
    "* Precisión en los resultados obtenidos (métricas de evaluación).\n",
    "* Calidad de las visualizaciones y del análisis de los resultados.\n",
    "* Rigor en la comparación de los modelos.\n",
    "* Creatividad en las conclusiones y en la presentación final.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1117f407-40e8-4dd5-b4db-05acb2f2d4b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
